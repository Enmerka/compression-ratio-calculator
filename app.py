# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UkcIO5NUPwdr8I02_AL_5XCvPx33B4cZ
"""

import streamlit as st
import requests
from bs4 import BeautifulSoup
import gzip
import pandas as pd
import matplotlib.pyplot as plt

# Define the app title
st.title("URL Compression Ratio Analyzer")

# User input for URL
url = st.text_input("Enter a URL:", "")

# Function to fetch and parse the webpage
def fetch_and_parse(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        with requests.Session() as session:
            response = session.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
    except requests.RequestException as e:
        st.error(f"Error fetching URL: {e}")
        return None
    return soup

# Function to calculate compression ratio
def calculate_compression_ratio(text):
    if not text:
        return 0
    original_size = len(text.encode('utf-8'))
    compressed_data = gzip.compress(text.encode('utf-8'))
    compressed_size = len(compressed_data)
    return original_size / compressed_size

# Analyze the URL when input is provided
if url:
    soup = fetch_and_parse(url)
    if soup:
        text = ' '.join([t.strip() for t in soup.stripped_strings])
        ratio = calculate_compression_ratio(text)
        st.write(f"Compression Ratio: {ratio:.2f}")